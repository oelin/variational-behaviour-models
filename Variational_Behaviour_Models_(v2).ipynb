{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Variational Behaviour Models"
      ],
      "metadata": {
        "id": "j7JB3Y-qHYe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this article we propose a probabilistic graphical model for the behaviour of an agent *embodied* within an environment."
      ],
      "metadata": {
        "id": "lolAappYHeHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Model"
      ],
      "metadata": {
        "id": "9M8lyM8OJrA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We consider a joint distribution of the form\n",
        "\n",
        "$$\n",
        "    \\begin{align}\n",
        "        p\\left(x^n, y^n, \\phi^n, \\psi^n\\right) = p(\\phi_1) p(\\psi_1) p(x_1|\\phi_1)p(y_1|\\psi_1)\\prod_{i=2}^n p(\\phi_i|\\phi_{i-1}, \\psi_{i-1}, y_{i-1}) p(\\psi_i|\\psi_{i-1},\\phi_{i-1},x_{i-1}) p(x_i|\\phi_i)p(y_i|\\psi_i),\n",
        "    \\end{align}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $x^n$ is a sequence of agent external states,\n",
        "- $y^n$ is a sequence of environment external states,\n",
        "- $\\phi^n$ is a sequence of agent internal states,\n",
        "- $\\psi^n$ is a sequence of enviornment internal states.\n",
        "\n",
        "This distribution expresses the interactions between an agent and it's environment. For non-embodied agents, we do not condition the agent's internal states on the environment's internal states, and visa-versa. Then, we recover a non-embodied behaviour model of the form\n",
        "\n",
        "$$\n",
        "    \\begin{align}\n",
        "        p\\left(x^n, y^n, \\phi^n, \\psi^n\\right) = p(\\phi_1) p(\\psi_1) p(x_1|\\phi_1)p(y_1|\\psi_1)\\prod_{i=2}^n p(\\phi_i|\\phi_{i-1}, y_{i-1}) p(\\psi_i|\\psi_{i-1},x_{i-1}) p(x_i|\\phi_i)p(y_i|\\psi_i).\n",
        "    \\end{align}\n",
        "$$\n",
        "\n",
        "In many situations, non-embodied models are reasonable. Now let us discuss each factor in turn.\n",
        "\n",
        "- **Agent prior model** - $p(\\phi_1)$. This is a prior over agent internal states.\n",
        "\n",
        "- **Environment prior model** - $p(\\psi_1)$. This is a prior over environment internal states.\n",
        "\n",
        "- **Agent emission model** - $p(x_i|\\phi_i)$. This is the distribution of agent external states given agent internal states. It generally represents how an agent's internal state influences its behaviour.\n",
        "\n",
        "- **Environment emission model** - $p(y_i|\\psi_i)$. This is the distribution of environment external states given environment internal states.\n",
        "\n",
        "- **Agent transition model** - $p(\\phi_i|\\phi_{i-1}, x_{i-1})$. This represents how agent internal states are influenced by external environment states.\n",
        "\n",
        "- **Environment transition model** - $p(\\psi_i|\\psi_{i-1}, y_{i-1})$. This represents how environment internal states are influenced by external agent states."
      ],
      "metadata": {
        "id": "pD_M76C9JtsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The whole system is essentially a pair of Hidden Markov Models (HMMs) whose internal states are influenced by eachother's external states."
      ],
      "metadata": {
        "id": "3eG5FYpXeN7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Parameter Estimation"
      ],
      "metadata": {
        "id": "8eXvIhjke7-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The established model involves latent variables so MLE is not directly applicable. An alternative approach is to maximize the variational lower-bound. For a partitioning of latent and observable variables ${Z, X}$, the variational lower bound on $p(X)$ can be written\n",
        "\n",
        "$$\n",
        "    \\begin{align}\n",
        "        \\mathcal{L} = \\mathbb{E}_{Z \\sim q(Z|X)}[\\log p(X|Z)] - D_\\text{KL}(q(Z|X)\\Vert \\pi(Z)),\n",
        "    \\end{align}\n",
        "$$\n",
        "\n",
        "where $q(Z|X)$ is a surrogate posterior and $\\pi(Z)$ is a prior over $Z$."
      ],
      "metadata": {
        "id": "zu0fIVn9e_Vb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our case, we have that $X = \\{x^n, y^n\\}$ and $Z = \\{\\phi^n, \\psi^n\\}$. Then the log-likelihood of is given by,\n",
        "\n",
        "$$\n",
        "    \\begin{align}\n",
        "        \\log p(X|Z) &= \\log p(x^n, y^n|\\phi^n, \\psi^n) \\\\\n",
        "        &= \\log p(x_1|\\phi_1) + \\log p(y_1|\\psi_1) + \\sum_{i=2}^n (\\log p(x_i|\\phi_i) + \\log p(y_i|\\psi_i)).\n",
        "    \\end{align}\n",
        "$$\n",
        "\n",
        "Meanwhile, the surrogate log-posterior is given by\n",
        "\n",
        "$$\n",
        "    \\begin{align}\n",
        "        \\log q(Z|X) &= \\log q(\\phi^n,\\psi^n|x^n,y^n) \\\\\n",
        "        &= \\log q(\\phi_1) + \\log q(\\psi_1) + \\sum_{i=2}^n \\left(\\log q(\\phi_i|\\phi_{i-1}, x_{i-1}) + \\log q(\\psi_i|\\psi_{i-1}, y_{i-1}) \\right).  \n",
        "    \\end{align}\n",
        "$$"
      ],
      "metadata": {
        "id": "QltL8VYFeunY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prior $\\pi(Z)$ serves to regularize the surrogate posterior. In practice, this can be achieved implicitly by quantizing the latents such that they take on discrete values from a set $K$. Alternatively, if the latents are vectors, we can ensure their dimension is substantially less than the external states, and that they're penalized for exhibiting high entropy distributions. For instance, if $q(\\phi_i|\\phi_{i-1},x_{i-1})$ is a Gaussian, we can penalize divergence from $\\mathcal{N}(0, 1)$."
      ],
      "metadata": {
        "id": "X0DvsLdLk1KM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In sum, the amortized loss for our model over an empirical dataset $\\mathcal{D} = \\{(x^n_1, y^n_1), \\dots, (x^n_m, y^n_m)\\}$ can be computed as follows:\n",
        "\n",
        "> For each sequence in $\\mathcal{D}$.\n",
        "> 1. Sample $\\phi_1, \\psi_1$ from the agent prior.\n",
        "> 2. Compute $A = \\log p(x_1|\\phi_1) + \\log p(y_1|\\psi_1)$ using the agent and environment emission models.\n",
        "> 3. Compute $B = \\sum_{i=2}^n \\left( \\log q(x_i|\\phi_i) + \\log q(y_i|\\psi_i) \\right)$ iteratively using the agent and environmen emission models. For sampling the latents, use the agent and environment transition models.\n",
        "> 4. Compute $C = \\sum_{i=1}^n R(\\phi_i, \\psi_i)$, where $R$ is a regularization measure such as KL divergence from $\\mathcal{N}(0, 1)$. It can also be implicit in the case of quantization.\n",
        "> 5. Compute $\\mathcal{L} = A + B + C$.\n",
        ">\n",
        "> Sum the $\\mathcal{L}$ losses for each sequence to obtain the final loss."
      ],
      "metadata": {
        "id": "QcxNCU98mXNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Neural Networks"
      ],
      "metadata": {
        "id": "j6tPhrFFr-4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In practice, we can parameterize our model using four neural networks. The first, known as the *agent encoder*, takes $x_i$ and $\\phi_{i-1}$ and returns a distribution over $\\phi_i$. This distribution may be discrete or continuous. The second, known as the *agent decoder*, takes a sample from $p(\\phi_i)$ and returns a distribution over $x_i$. These two networks parameterize the agent transition and emission models respectively."
      ],
      "metadata": {
        "id": "zwfJ-7tLsGFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Likewise, the environment models can be parameterized by an *environment encoder* and *environment decoder*. They perform a symmetric role to the agent networks."
      ],
      "metadata": {
        "id": "kpGQqHpRtGt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute the agent and environment priors, we have a few choices. We could *fix* them to simple distributions such as Gaussians. In this case, they have no free parameters and are not optimized during training. Alternatively we could learn their parameters."
      ],
      "metadata": {
        "id": "4pdi6dRstf4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Toy Implementations"
      ],
      "metadata": {
        "id": "U0US3uxdxsaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We experiment with simple incarnations of the outlined idea."
      ],
      "metadata": {
        "id": "cnNEsBqPxzI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  5.1. Discreate External States, Continuous Internal States"
      ],
      "metadata": {
        "id": "9S6ebJZKx4qf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we consider a simple model in which the agent and environment both emit discrete external states (specifically $x_i, y_i \\in \\{1, \\dots, K\\}$). Meanwhile, the latent states are modeled as continuous $D$-dimensional vectors. In reality, the hidden states of the agent and environment are discrete, however we are interested in whether the assumption of continuity still leads to strong performance."
      ],
      "metadata": {
        "id": "UssdljG1yAZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First let's implement the true data generating process."
      ],
      "metadata": {
        "id": "SfqzajmlyvVO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWxPtXxOGrYl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as dst\n",
        "\n",
        "\n",
        "def sample_real(sequence_length: int, batch_size: int) -> torch.Tensor:\n",
        "    \"\"\"Sample from the data generating process.\"\"\"\n",
        "\n",
        "    sequences = []\n",
        "\n",
        "    # Models.\n",
        "\n",
        "    agent_prior = dst.Categorical(probs=torch.tensor([0.1, 0.2, 0.3, 0.4]))\n",
        "    environment_prior = dst.Categorical(probs=torch.tensor([0.5, 0.1, 0.3, 0.1]))\n",
        "\n",
        "    agent_emission = {\n",
        "        0: dst.Categorical(probs=torch.tensor([0.4, 0.1, 0.1, 0.1, 0.1, 0.1])),\n",
        "        1: dst.Categorical(probs=torch.tensor([0.1, 0.3, 0.3, 0.1, 0.1, 0.1])),\n",
        "        2: dst.Categorical(probs=torch.tensor([0.6, 0.0, 0.0, 0.0, 0.2, 0.1])),\n",
        "        3: dst.Categorical(probs=torch.tensor([0.0, 0.1, 0.2, 0.0, 0.7, 0.0])),\n",
        "    }\n",
        "\n",
        "    environment_emission = {\n",
        "        0: dst.Categorical(probs=torch.tensor([0.0, 0.5, 0.1, 0.4, 0.0, 0.0])),\n",
        "        1: dst.Categorical(probs=torch.tensor([0.8, 0.1, 0.0, 0.0, 0.1, 0.0])),\n",
        "        2: dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.0, 0.7, 0.0, 0.3])),\n",
        "        3: dst.Categorical(probs=torch.tensor([0.0, 0.1, 0.1, 0.1, 0.7, 0.0])),\n",
        "    }\n",
        "\n",
        "    agent_transition = {\n",
        "        (0, 0): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.1, 0.9])),\n",
        "        (0, 1): dst.Categorical(probs=torch.tensor([0.7, 0.3, 0.0, 0.0])),\n",
        "        (0, 2): dst.Categorical(probs=torch.tensor([0.1, 0.0, 0.1, 0.8])),\n",
        "        (0, 3): dst.Categorical(probs=torch.tensor([0.0, 0.1, 0.0, 0.9])),\n",
        "        (0, 4): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.5, 0.5])),\n",
        "        (0, 5): dst.Categorical(probs=torch.tensor([0.5, 0.1, 0.4, 0.0])),\n",
        "\n",
        "        (1, 0): dst.Categorical(probs=torch.tensor([0.0, 0.4, 0.0, 0.6])),\n",
        "        (1, 1): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.3, 0.7])),\n",
        "        (1, 2): dst.Categorical(probs=torch.tensor([0.5, 0.0, 0.5, 0.0])),\n",
        "        (1, 3): dst.Categorical(probs=torch.tensor([0.3, 0.3, 0.4, 0.0])),\n",
        "        (1, 4): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.5, 0.5])),\n",
        "        (1, 5): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.7, 0.3])),\n",
        "\n",
        "        (2, 0): dst.Categorical(probs=torch.tensor([0.0, 0.4, 0.6, 0.0])),\n",
        "        (2, 1): dst.Categorical(probs=torch.tensor([0.0, 0.2, 0.8, 0.0])),\n",
        "        (2, 2): dst.Categorical(probs=torch.tensor([0.0, 0.8, 0.1, 0.1])),\n",
        "        (2, 3): dst.Categorical(probs=torch.tensor([0.3, 0.4, 0.3, 0.0])),\n",
        "        (2, 4): dst.Categorical(probs=torch.tensor([0.0, 0.1, 0.1, 0.8])),\n",
        "        (2, 5): dst.Categorical(probs=torch.tensor([0.1, 0.1, 0.0, 0.8])),\n",
        "\n",
        "        (3, 0): dst.Categorical(probs=torch.tensor([0.1, 0.0, 0.0, 0.9])),\n",
        "        (3, 1): dst.Categorical(probs=torch.tensor([0.7, 0.3, 0.3, 0.0])),\n",
        "        (3, 2): dst.Categorical(probs=torch.tensor([0.1, 0.7, 0.1, 0.1])),\n",
        "        (3, 3): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.5, 0.5])),\n",
        "        (3, 4): dst.Categorical(probs=torch.tensor([0.2, 0.2, 0.0, 0.6])),\n",
        "        (3, 5): dst.Categorical(probs=torch.tensor([0.2, 0.8, 0.0, 0.1])),\n",
        "    }\n",
        "\n",
        "    environment_transition = agent_transition\n",
        "    # environment_transition = {\n",
        "    #     (0, 0): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.1, 0.9])),\n",
        "    #     (0, 1): dst.Categorical(probs=torch.tensor([0.7, 0.3, 0.0, 0.0])),\n",
        "    #     (0, 2): dst.Categorical(probs=torch.tensor([0.1, 0.0, 0.1, 0.8])),\n",
        "    #     (0, 3): dst.Categorical(probs=torch.tensor([0.0, 0.1, 0.0, 0.9])),\n",
        "    #     (0, 4): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.5, 0.5])),\n",
        "    #     (0, 5): dst.Categorical(probs=torch.tensor([0.5, 0.1, 0.4, 0.0])),\n",
        "\n",
        "    #     (1, 0): dst.Categorical(probs=torch.tensor([0.0, 0.4, 0.0, 0.6])),\n",
        "    #     (1, 1): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.3, 0.7])),\n",
        "    #     (1, 2): dst.Categorical(probs=torch.tensor([0.5, 0.0, 0.5, 0.0])),\n",
        "    #     (1, 3): dst.Categorical(probs=torch.tensor([0.3, 0.3, 0.4, 0.0])),\n",
        "    #     (1, 4): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.5, 0.5])),\n",
        "    #     (1, 5): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.7, 0.3])),\n",
        "\n",
        "    #     (2, 0): dst.Categorical(probs=torch.tensor([0.0, 0.4, 0.6, 0.0])),\n",
        "    #     (2, 1): dst.Categorical(probs=torch.tensor([0.0, 0.2, 0.8, 0.0])),\n",
        "    #     (2, 2): dst.Categorical(probs=torch.tensor([0.0, 0.8, 0.1, 0.1])),\n",
        "    #     (2, 3): dst.Categorical(probs=torch.tensor([0.3, 0.4, 0.3, 0.0])),\n",
        "    #     (2, 4): dst.Categorical(probs=torch.tensor([0.0, 0.1, 0.1, 0.8])),\n",
        "    #     (2, 5): dst.Categorical(probs=torch.tensor([0.1, 0.1, 0.0, 0.8])),\n",
        "\n",
        "    #     (3, 0): dst.Categorical(probs=torch.tensor([0.1, 0.0, 0.0, 0.9])),\n",
        "    #     (3, 1): dst.Categorical(probs=torch.tensor([0.7, 0.3, 0.3, 0.0])),\n",
        "    #     (3, 2): dst.Categorical(probs=torch.tensor([0.1, 0.7, 0.1, 0.1])),\n",
        "    #     (3, 3): dst.Categorical(probs=torch.tensor([0.0, 0.0, 0.5, 0.5])),\n",
        "    #     (3, 4): dst.Categorical(probs=torch.tensor([0.2, 0.2, 0.0, 0.6])),\n",
        "    #     (3, 5): dst.Categorical(probs=torch.tensor([0.2, 0.8, 0.0, 0.1])),\n",
        "    # }\n",
        "\n",
        "    # Sampling.\n",
        "\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for _ in range(batch_size):\n",
        "\n",
        "        # Sample initial internal states.\n",
        "\n",
        "        phi = agent_prior.sample().item()\n",
        "        psi = environment_prior.sample().item()\n",
        "\n",
        "        # Sample initial external states.\n",
        "\n",
        "        x = agent_emission[phi].sample().item()\n",
        "        y = environment_emission[psi].sample().item()\n",
        "\n",
        "        # Sample remaining internal and external states.\n",
        "\n",
        "        for i in range(sequence_length):\n",
        "\n",
        "            xs.append(x)\n",
        "            ys.append(y)\n",
        "\n",
        "            phi = agent_transition[(phi, y)].sample().item()\n",
        "            psi = environment_transition[(psi, x)].sample().item()\n",
        "            x = agent_emission[phi].sample().item()\n",
        "            y = environment_emission[psi].sample().item()\n",
        "\n",
        "\n",
        "    xs = torch.tensor(xs, dtype=torch.int64).view(batch_size, sequence_length)\n",
        "    ys = torch.tensor(ys, dtype=torch.int64).view(batch_size, sequence_length)\n",
        "\n",
        "    return xs, ys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_real(20, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaAlTyxszYuj",
        "outputId": "72b857ed-c722-44e0-f9f8-6b792daa5a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[4, 4, 4, 4, 4, 0, 4, 0, 1, 4, 4, 0, 0, 2, 5, 4, 0, 5, 2, 2],\n",
              "         [0, 3, 0, 0, 4, 2, 0, 2, 0, 2, 4, 4, 2, 2, 4, 2, 4, 1, 4, 1],\n",
              "         [4, 0, 4, 2, 4, 4, 4, 4, 0, 1, 4, 4, 4, 0, 2, 0, 0, 4, 4, 4],\n",
              "         [1, 0, 0, 2, 2, 0, 0, 1, 0, 4, 1, 1, 1, 4, 0, 0, 1, 4, 5, 0],\n",
              "         [0, 4, 0, 4, 0, 4, 1, 0, 4, 4, 1, 2, 1, 4, 4, 0, 3, 0, 4, 4]],\n",
              "        dtype=torch.int8),\n",
              " tensor([[1, 4, 4, 0, 5, 3, 4, 4, 0, 4, 1, 5, 0, 1, 0, 3, 1, 2, 0, 3],\n",
              "         [3, 5, 0, 4, 1, 4, 0, 2, 0, 0, 3, 1, 4, 0, 3, 4, 4, 0, 4, 0],\n",
              "         [3, 5, 5, 4, 3, 5, 4, 1, 3, 0, 4, 4, 4, 1, 2, 1, 4, 3, 4, 4],\n",
              "         [3, 3, 3, 0, 3, 1, 3, 2, 0, 4, 4, 3, 0, 2, 4, 4, 4, 1, 3, 2],\n",
              "         [0, 4, 4, 1, 3, 1, 4, 5, 3, 2, 4, 1, 4, 0, 2, 2, 3, 4, 4, 0]],\n",
              "        dtype=torch.int8))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "\n",
        "internal_cardinality = 4\n",
        "external_cardinality = 6\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        input_dimension: int,\n",
        "        latent_dimension: int,\n",
        "        hidden_dimension: int,\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize the module.\"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_features=input_dimension + latent_dimension, out_features=hidden_dimension),\n",
        "            nn.Tanh(),\n",
        "            nn.LayerNorm(normalized_shape=hidden_dimension),\n",
        "            nn.Linear(in_features=hidden_dimension, out_features=hidden_dimension // 2 + latent_dimension),\n",
        "            nn.Tanh(),\n",
        "            nn.LayerNorm(normalized_shape=hidden_dimension // 2 + latent_dimension),\n",
        "            nn.Linear(in_features=hidden_dimension // 2 + latent_dimension, out_features=latent_dimension),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward the module.\"\"\"\n",
        "\n",
        "        return self.layers(torch.cat((x, z), dim=-1))\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        input_dimension: int,\n",
        "        latent_dimension: int,\n",
        "        hidden_dimension: int,\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize the module.\"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_features=latent_dimension, out_features=hidden_dimension // 2 + latent_dimension),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(normalized_shape=hidden_dimension // 2 + latent_dimension),\n",
        "            nn.Linear(in_features=hidden_dimension // 2 + latent_dimension, out_features=hidden_dimension),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.LayerNorm(normalized_shape=hidden_dimension),\n",
        "            nn.Linear(in_features=hidden_dimension, out_features=input_dimension),\n",
        "            nn.LogSoftmax(dim=-1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward the module.\"\"\"\n",
        "\n",
        "        return self.layers(z)\n",
        "\n",
        "\n",
        "class VBM(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        input_dimension: int,\n",
        "        latent_dimension: int,\n",
        "        hidden_dimension: int,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dimension = input_dimension\n",
        "        self.latent_dimension = latent_dimension\n",
        "\n",
        "        self.agent_encoder = Encoder(\n",
        "            input_dimension=input_dimension,\n",
        "            latent_dimension=latent_dimension,\n",
        "            hidden_dimension=hidden_dimension,\n",
        "        )\n",
        "\n",
        "        self.agent_decoder = Decoder(\n",
        "            input_dimension=input_dimension,\n",
        "            latent_dimension=latent_dimension,\n",
        "            hidden_dimension=hidden_dimension,\n",
        "        )\n",
        "\n",
        "        self.environment_encoder = Encoder(\n",
        "            input_dimension=input_dimension,\n",
        "            latent_dimension=latent_dimension,\n",
        "            hidden_dimension=hidden_dimension,\n",
        "        )\n",
        "\n",
        "        self.environment_decoder = Decoder(\n",
        "            input_dimension=input_dimension,\n",
        "            latent_dimension=latent_dimension,\n",
        "            hidden_dimension=hidden_dimension,\n",
        "        )\n",
        "\n",
        "    def sample_prior(self, batch_size: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "\n",
        "        phi = torch.randn((batch_size, self.latent_dimension))\n",
        "        psi = torch.randn((batch_size, self.latent_dimension))\n",
        "\n",
        "        return phi, psi\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        y: torch.Tensor,\n",
        "        phi: torch.Tensor,\n",
        "        psi: torch.Tensor,\n",
        "    ) -> Tuple[\n",
        "        torch.Tensor,\n",
        "        torch.Tensor,\n",
        "        torch.Tensor,\n",
        "        torch.Tensor,\n",
        "        torch.Tensor,\n",
        "        torch.Tensor,\n",
        "    ]:\n",
        "        # Forward pass for a single time step.\n",
        "\n",
        "        x = F.one_hot(x, num_classes=self.input_dimension)\n",
        "        y = F.one_hot(y, num_classes=self.input_dimension)\n",
        "\n",
        "        phi_mean = self.agent_encoder(y, phi)\n",
        "        psi_mean = self.environment_encoder(x, psi)\n",
        "\n",
        "        phi = phi_mean + torch.randn_like(phi_mean, device=x.device)\n",
        "        psi = psi_mean + torch.randn_like(psi_mean, device=x.device)\n",
        "\n",
        "        x_hat = self.agent_decoder(phi)\n",
        "        y_hat = self.environment_decoder(psi)\n",
        "\n",
        "        return x_hat, y_hat, phi, psi, phi_mean, psi_mean"
      ],
      "metadata": {
        "id": "b-2x0Azg0Rj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vbm_loss(x_batch: torch.Tensor, y_batch: torch.Tensor, vbm: VBM, kl_weight: float) -> torch.Tensor:\n",
        "\n",
        "    batch_size, sequence_length = x_batch.shape\n",
        "    phi, psi = vbm.sample_prior(batch_size)\n",
        "    loss = 0.\n",
        "\n",
        "    for i in range(1, sequence_length):\n",
        "\n",
        "        x = x_batch[:, i]  # Shape: (B,)\n",
        "        y = y_batch[:, i]\n",
        "        x_hat, y_hat, phi, psi, phi_mean, psi_mean = vbm(x, y, phi.detach(), psi.detach())\n",
        "\n",
        "        kl_loss = torch.square(phi_mean).mean() + torch.square(psi_mean).mean()  # Squared distance from 0.\n",
        "        reconstruction_loss = F.nll_loss(x_hat, x, reduction='mean') + F.nll_loss(y_hat, y, reduction='mean')\n",
        "\n",
        "        loss = loss + reconstruction_loss + (kl_weight * kl_loss)\n",
        "\n",
        "    return loss / sequence_length"
      ],
      "metadata": {
        "id": "3LVYOwyYHWDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VBM(input_dimension=6, latent_dimension=2, hidden_dimension=16)"
      ],
      "metadata": {
        "id": "3ParzUuoNdnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "batch_size = 32\n",
        "batches_per_epoch = 100\n",
        "sequence_length = 10\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(batches_per_epoch):\n",
        "\n",
        "        x_batch, y_batch = sample_real(sequence_length, batch_size)\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        loss = vbm_loss(x_batch, y_batch, model, kl_weight=0.0)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if (batch % 10) == 0:\n",
        "            print(f'epoch: {epoch:03d}, batch: {batch:03d} - loss: {loss.detach().item():0.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bMkiiVHtM7aj",
        "outputId": "a029aa7f-ed57-4b5f-aa81-0f94ecd2b7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 000, batch: 000 - loss: 3.44289\n",
            "epoch: 000, batch: 010 - loss: 2.89749\n",
            "epoch: 000, batch: 020 - loss: 2.93161\n",
            "epoch: 000, batch: 030 - loss: 2.84779\n",
            "epoch: 000, batch: 040 - loss: 2.79713\n",
            "epoch: 000, batch: 050 - loss: 2.84976\n",
            "epoch: 000, batch: 060 - loss: 2.82584\n",
            "epoch: 000, batch: 070 - loss: 2.84785\n",
            "epoch: 000, batch: 080 - loss: 2.82977\n",
            "epoch: 000, batch: 090 - loss: 2.80417\n",
            "epoch: 001, batch: 000 - loss: 2.76226\n",
            "epoch: 001, batch: 010 - loss: 2.82369\n",
            "epoch: 001, batch: 020 - loss: 2.82867\n",
            "epoch: 001, batch: 030 - loss: 2.80269\n",
            "epoch: 001, batch: 040 - loss: 2.88523\n",
            "epoch: 001, batch: 050 - loss: 2.90603\n",
            "epoch: 001, batch: 060 - loss: 2.90612\n",
            "epoch: 001, batch: 070 - loss: 2.88173\n",
            "epoch: 001, batch: 080 - loss: 2.78233\n",
            "epoch: 001, batch: 090 - loss: 2.82023\n",
            "epoch: 002, batch: 000 - loss: 2.80457\n",
            "epoch: 002, batch: 010 - loss: 2.77553\n",
            "epoch: 002, batch: 020 - loss: 2.83040\n",
            "epoch: 002, batch: 030 - loss: 2.92179\n",
            "epoch: 002, batch: 040 - loss: 2.80141\n",
            "epoch: 002, batch: 050 - loss: 2.85230\n",
            "epoch: 002, batch: 060 - loss: 2.79922\n",
            "epoch: 002, batch: 070 - loss: 2.67172\n",
            "epoch: 002, batch: 080 - loss: 2.86655\n",
            "epoch: 002, batch: 090 - loss: 2.85057\n",
            "epoch: 003, batch: 000 - loss: 2.83719\n",
            "epoch: 003, batch: 010 - loss: 2.79216\n",
            "epoch: 003, batch: 020 - loss: 2.78073\n",
            "epoch: 003, batch: 030 - loss: 2.84036\n",
            "epoch: 003, batch: 040 - loss: 2.80378\n",
            "epoch: 003, batch: 050 - loss: 2.82190\n",
            "epoch: 003, batch: 060 - loss: 2.78989\n",
            "epoch: 003, batch: 070 - loss: 2.78008\n",
            "epoch: 003, batch: 080 - loss: 2.88737\n",
            "epoch: 003, batch: 090 - loss: 2.85738\n",
            "epoch: 004, batch: 000 - loss: 2.90208\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-b63ed3cf6eda>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvbm_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vbm = VBM(input_dimension=6, latent_dimension=2, hidden_dimension=16)"
      ],
      "metadata": {
        "id": "1qgHbSKH_8V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = sample_real(sequence_length=10, batch_size=8)"
      ],
      "metadata": {
        "id": "ZmydYAFGHMQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vbm_loss(x_batch, y_batch, vbm, kl_weight=1.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKyej5IfJDFG",
        "outputId": "9f7ac114-6473-4e5b-b847-aaf7a786c2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3466, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj7g4xKxJK56",
        "outputId": "dd1be87b-7d06-4912-f05d-160ee447ff58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 2, 2, 1, 2, 4, 3, 2, 2, 0],\n",
              "        [4, 1, 4, 1, 4, 2, 4, 4, 0, 4],\n",
              "        [2, 4, 2, 2, 2, 2, 5, 4, 0, 0],\n",
              "        [2, 0, 2, 4, 4, 4, 4, 0, 0, 4],\n",
              "        [4, 0, 0, 5, 0, 0, 1, 2, 5, 4],\n",
              "        [2, 2, 1, 3, 4, 0, 5, 0, 0, 4],\n",
              "        [4, 5, 4, 2, 2, 4, 0, 4, 4, 1],\n",
              "        [2, 0, 2, 4, 2, 0, 4, 4, 4, 5]], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNXAEDdhJcNy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}